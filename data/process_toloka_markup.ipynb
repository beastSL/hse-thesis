{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from crowdkit.aggregation import Wawa\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mv_or_median(x):\n",
    "    vc = x.value_counts()\n",
    "    if vc.values[0] == 1:\n",
    "        return int(np.median(x))\n",
    "    else:\n",
    "        return int(vc.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wawa_score(scores):\n",
    "    return Wawa().fit_predict(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unaligned_workers(scores_path, threshold=0.35):\n",
    "    toloka_markup = pd.read_csv(scores_path, sep='\\t').drop([\"GOLDEN:is_subjective\", \"HINT:text\", \"HINT:default_language\"], axis=1)\n",
    "    toloka_markup['OUTPUT:is_subjective'].replace({2: 1, 3: 2, 4: 3, 5: 3}, inplace=True)\n",
    "\n",
    "    wawa_score = get_wawa_score(toloka_markup)\n",
    "\n",
    "    worker_ids = toloka_markup.value_counts(\"ASSIGNMENT:worker_id\").index\n",
    "    worker_f1s = []\n",
    "    for worker_id in worker_ids:\n",
    "        worker_scores = toloka_markup[toloka_markup['ASSIGNMENT:worker_id'] == worker_id][['ASSIGNMENT:task_id', 'OUTPUT:is_subjective']]\n",
    "        worker_scores = worker_scores.set_index('ASSIGNMENT:task_id')\n",
    "        worker_scores['wawa'] = wawa_score[wawa_score.index.isin(worker_scores.index)]\n",
    "        worker_f1s.append(f1_score(worker_scores['wawa'], worker_scores['OUTPUT:is_subjective'], average='macro'))\n",
    "    wawa_worker_ratings = pd.Series(data=worker_f1s, index=worker_ids)\n",
    "    return wawa_worker_ratings[wawa_worker_ratings < 0.35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_label_distribution(scores_path):\n",
    "    toloka_markup = pd.read_csv(scores_path, sep='\\t').drop([\"GOLDEN:is_subjective\", \"HINT:text\", \"HINT:default_language\"], axis=1)\n",
    "    toloka_markup['OUTPUT:is_subjective'].replace({2: 1, 3: 2, 4: 3, 5: 3}, inplace=True)\n",
    "\n",
    "    wawa_score = get_wawa_score(toloka_markup)\n",
    "\n",
    "    vc = wawa_score.value_counts()\n",
    "    print(f\"Sentences with the 'Non-Applicable' label: {vc[0]}\")\n",
    "    print(f\"Sentences with the 'Objective' label: {vc[1]}\")\n",
    "    print(f\"Sentences with the 'Neutral' label: {vc[2]}\")\n",
    "    print(f\"Sentences with the 'Subjective' label: {vc[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_scores(scores_path, sentence_id_retrieval_path):\n",
    "    toloka_markup = pd.read_csv(scores_path, sep='\\t').drop([\"GOLDEN:is_subjective\", \"HINT:text\", \"HINT:default_language\"], axis=1)\n",
    "    toloka_markup['OUTPUT:is_subjective'].replace({2: 1, 3: 2, 4: 3, 5: 3}, inplace=True)\n",
    "\n",
    "    sentence_ids_by_text = pd.read_csv(sentence_id_retrieval_path, sep='\\t').set_index(\"INPUT:text\")\n",
    "\n",
    "    wawa_score = get_wawa_score(toloka_markup)\n",
    "    \n",
    "    wawa_score_df = pd.DataFrame(wawa_score).rename(columns={\"agg_label\": \"score\"})\n",
    "    wawa_score_df = wawa_score_df.join(toloka_markup[[\"INPUT:text\", \"ASSIGNMENT:task_id\"]].drop_duplicates().set_index(\"ASSIGNMENT:task_id\"))\n",
    "    wawa_score_df[\"INPUT:text\"] = wawa_score_df[\"INPUT:text\"].str.replace(\"\\r\", \"\")\n",
    "    wawa_score_df = wawa_score_df.set_index(\"INPUT:text\").join(sentence_ids_by_text).reset_index().drop(\"INPUT:text\", axis=1)\n",
    "    wawa_score_df = wawa_score_df.groupby(by=\"sentence_id\")['score'].apply(list).reset_index().explode('score')\n",
    "\n",
    "    print(wawa_score_df.isna().value_counts()[False].item())\n",
    "    assert wawa_score_df.isna().value_counts()[False] == len(wawa_score_df)\n",
    "\n",
    "    return wawa_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_task_id_into_sentence_id(scores_path, sentence_id_retrieval_path):\n",
    "    toloka_markup = pd.read_csv(scores_path, sep='\\t')[['INPUT:text', 'OUTPUT:is_subjective', 'ASSIGNMENT:worker_id']]\n",
    "    toloka_markup[\"INPUT:text\"] = toloka_markup[\"INPUT:text\"].str.replace(\"\\r\", \"\")\n",
    "    toloka_markup = toloka_markup.rename(columns={\n",
    "        'INPUT:text': 'text',\n",
    "        'OUTPUT:is_subjective': 'label',\n",
    "        'ASSIGNMENT:worker_id' : 'worker'\n",
    "    }).set_index('text')\n",
    "    toloka_markup['label'].replace({2: 1, 3: 2, 4: 3, 5: 3}, inplace=True)\n",
    "    sentence_ids_by_text = pd.read_csv(sentence_id_retrieval_path, sep='\\t').set_index(\"INPUT:text\")\n",
    "    return toloka_markup.join(sentence_ids_by_text).reset_index(drop=True).rename(columns={'sentence_id': 'task'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_with_data_and_split(aggregated_scores, data_path):\n",
    "    \n",
    "    train_val, test = train_test_split(data, test_size=0.2, stratify=data['score'])\n",
    "    train, val = train_test_split(train_val, test_size=0.1, stratify=train_val['score'])\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_unaligned_workers(\"testing_scores.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_unaligned_workers(\"full_scores.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with the 'Non-Applicable' label: 15\n",
      "Sentences with the 'Objective' label: 52\n",
      "Sentences with the 'Neutral' label: 1\n",
      "Sentences with the 'Subjective' label: 89\n"
     ]
    }
   ],
   "source": [
    "print_label_distribution(\"testing_scores.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with the 'Non-Applicable' label: 1236\n",
      "Sentences with the 'Objective' label: 14222\n",
      "Sentences with the 'Neutral' label: 388\n",
      "Sentences with the 'Subjective' label: 3861\n"
     ]
    }
   ],
   "source": [
    "print_label_distribution(\"full_scores.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_scores = pd.read_csv(\"sample_scores.csv\").replace({2: 1, 3: 2, 4: 3, 5: 3}).rename(columns={\n",
    "    'sentence_id': 'task',\n",
    "    'score': 'label'\n",
    "})\n",
    "sample_scores['worker'] = [1000] * len(sample_scores)\n",
    "testing_scores = map_task_id_into_sentence_id(\"testing_scores.tsv\", \"testing_dataset_for_retrieval.tsv\")\n",
    "full_scores = map_task_id_into_sentence_id(\"full_scores.tsv\", \"full_dataset_for_retrieval.tsv\")\n",
    "scores = pd.concat([sample_scores, testing_scores, full_scores]).set_index('task')\n",
    "scores = scores.join(pd.read_csv(\"sent_tokenized_dataset.csv\").set_index('sentence_id')).reset_index(drop=False)\n",
    "labels = scores.groupby(\"text\")['label'].apply(list)\n",
    "workers = scores.groupby(\"text\")['worker'].apply(list)\n",
    "labels_and_workers = list(map(lambda x : list(zip(x[0], x[1])), zip(labels, workers)))\n",
    "tasks = scores.groupby(\"text\")['index'].apply(lambda x : x.values[0]).to_frame().rename(columns={'index': 'task'})\n",
    "tasks['labels_and_workers'] = labels_and_workers\n",
    "tasks = tasks.explode('labels_and_workers')\n",
    "tasks['label'] = tasks['labels_and_workers'].apply(lambda x : x[0])\n",
    "tasks['worker'] = tasks['labels_and_workers'].apply(lambda x : x[1])\n",
    "tasks = tasks.drop('labels_and_workers', axis=1).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task</th>\n",
       "      <th>label</th>\n",
       "      <th>worker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" Why did not he ask for the Var's intervention?</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0</td>\n",
       "      <td>043b91a462150036c59d74c7673289d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\" Why did not he ask for the Var's intervention?</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0</td>\n",
       "      <td>693620efb636e2672ee2fbcf8ea27958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" Why did not he ask for the Var's intervention?</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3b972756883087c59eafe6aac630ed66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\"SELF HARM\"Rouhani, in Vienna trying to salva...</td>\n",
       "      <td>11549.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c736d37f31974f5849676c2ce3aff58f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\"SELF HARM\"Rouhani, in Vienna trying to salva...</td>\n",
       "      <td>11549.0</td>\n",
       "      <td>1</td>\n",
       "      <td>538d04a5c8dfddc2afa3a09f01b5ddd4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65340</th>\n",
       "      <td>… just because somebody was born in an era tha...</td>\n",
       "      <td>15600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>a311d48ee766b6e696228ffe2b731f5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65341</th>\n",
       "      <td>… just because somebody was born in an era tha...</td>\n",
       "      <td>15600.0</td>\n",
       "      <td>3</td>\n",
       "      <td>93791c5031b66bd658426b231bff8ebb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65342</th>\n",
       "      <td>😉”\\n“‘Spero,’ which is Latin for ‘hope’ and al...</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1</td>\n",
       "      <td>cf595f6a413a62ac8d4a43e953bb4593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65343</th>\n",
       "      <td>😉”\\n“‘Spero,’ which is Latin for ‘hope’ and al...</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1</td>\n",
       "      <td>890447284f0273f92a64c544375d59ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65344</th>\n",
       "      <td>😉”\\n“‘Spero,’ which is Latin for ‘hope’ and al...</td>\n",
       "      <td>171.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3cd83ef049722ae42acde9dd823c880a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65345 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     task  label  \\\n",
       "0       \" Why did not he ask for the Var's intervention?   3261.0      0   \n",
       "1       \" Why did not he ask for the Var's intervention?   3261.0      0   \n",
       "2       \" Why did not he ask for the Var's intervention?   3261.0      0   \n",
       "3      \"\"SELF HARM\"Rouhani, in Vienna trying to salva...  11549.0      1   \n",
       "4      \"\"SELF HARM\"Rouhani, in Vienna trying to salva...  11549.0      1   \n",
       "...                                                  ...      ...    ...   \n",
       "65340  … just because somebody was born in an era tha...  15600.0      0   \n",
       "65341  … just because somebody was born in an era tha...  15600.0      3   \n",
       "65342  😉”\\n“‘Spero,’ which is Latin for ‘hope’ and al...    171.0      1   \n",
       "65343  😉”\\n“‘Spero,’ which is Latin for ‘hope’ and al...    171.0      1   \n",
       "65344  😉”\\n“‘Spero,’ which is Latin for ‘hope’ and al...    171.0      3   \n",
       "\n",
       "                                 worker  \n",
       "0      043b91a462150036c59d74c7673289d5  \n",
       "1      693620efb636e2672ee2fbcf8ea27958  \n",
       "2      3b972756883087c59eafe6aac630ed66  \n",
       "3      c736d37f31974f5849676c2ce3aff58f  \n",
       "4      538d04a5c8dfddc2afa3a09f01b5ddd4  \n",
       "...                                 ...  \n",
       "65340  a311d48ee766b6e696228ffe2b731f5e  \n",
       "65341  93791c5031b66bd658426b231bff8ebb  \n",
       "65342  cf595f6a413a62ac8d4a43e953bb4593  \n",
       "65343  890447284f0273f92a64c544375d59ee  \n",
       "65344  3cd83ef049722ae42acde9dd823c880a  \n",
       "\n",
       "[65345 rows x 4 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task\n",
       "0.0        1\n",
       "1.0        1\n",
       "2.0        1\n",
       "3.0        1\n",
       "6.0        1\n",
       "          ..\n",
       "19947.0    1\n",
       "19948.0    1\n",
       "19949.0    1\n",
       "19951.0    1\n",
       "19952.0    1\n",
       "Name: agg_label, Length: 18334, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_scores = get_wawa_score(tasks)\n",
    "aggregated_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train, val, test \u001b[38;5;241m=\u001b[39m \u001b[43mjoin_with_data_and_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggregated_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msent_tokenized_dataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m train\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m val\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [35], line 3\u001b[0m, in \u001b[0;36mjoin_with_data_and_split\u001b[0;34m(aggregated_scores, data_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin_with_data_and_split\u001b[39m(aggregated_scores, data_path):\n\u001b[1;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_path)\u001b[38;5;241m.\u001b[39mjoin(aggregated_scores, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_mv_or_median\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      4\u001b[0m     train_val, test \u001b[38;5;241m=\u001b[39m train_test_split(data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m     train, val \u001b[38;5;241m=\u001b[39m train_test_split(train_val, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mtrain_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/groupby/generic.py:223\u001b[0m, in \u001b[0;36mSeriesGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39m@Appender\u001b[39m(\n\u001b[1;32m    218\u001b[0m     _apply_docs[\u001b[39m\"\u001b[39m\u001b[39mtemplate\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    219\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m, examples\u001b[39m=\u001b[39m_apply_docs[\u001b[39m\"\u001b[39m\u001b[39mseries_examples\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    220\u001b[0m     )\n\u001b[1;32m    221\u001b[0m )\n\u001b[1;32m    222\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1275\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1274\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1275\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_apply_general(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selected_obj)\n\u001b[1;32m   1276\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m         \u001b[39m# gh-20949\u001b[39;00m\n\u001b[1;32m   1278\u001b[0m         \u001b[39m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[39m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m         \u001b[39m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m         \u001b[39mwith\u001b[39;00m group_selection_context(\u001b[39mself\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1309\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_apply_general\u001b[39m(\n\u001b[1;32m   1292\u001b[0m     \u001b[39mself\u001b[39m, f: F, data: FrameOrSeriesUnion\n\u001b[1;32m   1293\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FrameOrSeriesUnion:\n\u001b[1;32m   1294\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m \u001b[39m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[39m        data after applying f\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1309\u001b[0m     keys, values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49mapply(f, data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n\u001b[1;32m   1311\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_applied_output(\n\u001b[1;32m   1312\u001b[0m         data, keys, values, not_indexed_same\u001b[39m=\u001b[39mmutated \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutated\n\u001b[1;32m   1313\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/groupby/ops.py:841\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[39m# group might be modified\u001b[39;00m\n\u001b[1;32m    840\u001b[0m group_axes \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39maxes\n\u001b[0;32m--> 841\u001b[0m res \u001b[39m=\u001b[39m f(group)\n\u001b[1;32m    842\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    843\u001b[0m     mutated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [6], line 3\u001b[0m, in \u001b[0;36mget_mv_or_median\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mv_or_median\u001b[39m(x):\n\u001b[1;32m      2\u001b[0m     vc \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmedian(x))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "train, val, test = join_with_data_and_split(aggregated_scores, 'sent_tokenized_dataset.csv')\n",
    "\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "val.to_csv(\"val.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10263\n",
       "3     2819\n",
       "0      911\n",
       "2      372\n",
       "Name: is_subjective, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train['is_subjective'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
